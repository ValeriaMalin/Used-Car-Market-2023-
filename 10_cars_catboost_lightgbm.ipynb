{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d061388c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score, mean_absolute_error\n",
    "import scipy.stats as stats\n",
    "\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59eaa7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.7-cp311-cp311-macosx_11_0_universal2.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: graphviz in ./anaconda3/lib/python3.11/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in ./anaconda3/lib/python3.11/site-packages (from catboost) (3.7.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in ./anaconda3/lib/python3.11/site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24 in ./anaconda3/lib/python3.11/site-packages (from catboost) (2.0.3)\n",
      "Requirement already satisfied: scipy in ./anaconda3/lib/python3.11/site-packages (from catboost) (1.11.1)\n",
      "Requirement already satisfied: plotly in ./anaconda3/lib/python3.11/site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.11/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./anaconda3/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./anaconda3/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./anaconda3/lib/python3.11/site-packages (from plotly->catboost) (8.2.2)\n",
      "Downloading catboost-1.2.7-cp311-cp311-macosx_11_0_universal2.whl (27.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.1/27.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: catboost\n",
      "Successfully installed catboost-1.2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01922b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.5.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in ./anaconda3/lib/python3.11/site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in ./anaconda3/lib/python3.11/site-packages (from lightgbm) (1.11.1)\n",
      "Downloading lightgbm-4.5.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "465a8829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#: Import CatBoost or LightGBM and run your models\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c4c280c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 238221 entries, 0 to 238301\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   brand                     238221 non-null  object \n",
      " 1   model                     238221 non-null  object \n",
      " 2   color                     238221 non-null  object \n",
      " 3   price_in_euro             238221 non-null  float64\n",
      " 4   power_ps                  238221 non-null  float64\n",
      " 5   transmission_type         238221 non-null  object \n",
      " 6   fuel_type                 238221 non-null  object \n",
      " 7   fuel_consumption_l_100km  238221 non-null  float64\n",
      " 8   mileage_in_km             238221 non-null  float64\n",
      " 9   age                       238221 non-null  float64\n",
      "dtypes: float64(5), object(5)\n",
      "memory usage: 20.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "#cleaned dataset\n",
    "df = pd.read_csv(\"auto_data_cleaned_16_09_2024.csv\")\n",
    "# Example setup of columns, adjust based on your dataset structure\n",
    "\n",
    "df=df.drop(columns=['year', 'offer_description'])\n",
    "df = df.dropna(subset=['color'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5763a38",
   "metadata": {},
   "source": [
    "## Catboost model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fad17c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CatBoost Model...\n",
      "CatBoost MAE: 3805.5119981235016\n",
      "Test R² - full dataset: 0.8779305478439742\n",
      "Test Set MSE - full dataset: 142725576.05539766\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "#cleaned dataset\n",
    "# setup of features\n",
    "target = 'price_in_euro'\n",
    "numerical_features = ['age', 'power_ps', 'fuel_consumption_l_100km', 'mileage_in_km']\n",
    "categorical_features = ['color', 'model', 'brand', 'fuel_type', 'transmission_type']\n",
    "\n",
    "# Splitting data into X and y\n",
    "X = df[numerical_features + categorical_features]\n",
    "y = df[target]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "### CatBoost Model ###\n",
    "print(\"Training CatBoost Model...\")\n",
    "catboost_model = CatBoostRegressor(cat_features=categorical_features, verbose=0)  # Setting categorical features\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate CatBoost\n",
    "y_pred_catboost = catboost_model.predict(X_test)\n",
    "mae_catboost = mean_absolute_error(y_test, y_pred_catboost)\n",
    "print(f\"CatBoost MAE: {mae_catboost}\")\n",
    "\n",
    "test_r2 = r2_score(y_test, y_pred_catboost)\n",
    "print(f\"Test R² - full dataset: {test_r2}\")\n",
    "mse_test = mean_squared_error(y_test, y_pred_catboost)\n",
    "print(f\"Test Set MSE - full dataset: {mse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c588c77b",
   "metadata": {},
   "source": [
    "### Dataset without extreme price values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b70fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data \n",
    "#cleaned dataset\n",
    "df = pd.read_csv(\"auto_data_cleaned_16_09_2024.csv\")\n",
    "\n",
    "#  setup of features, adjust based on your dataset structure\n",
    "\n",
    "df=df.drop(columns=['year', 'offer_description'])\n",
    "df = df.dropna(subset=['color'])\n",
    "\n",
    "\n",
    "# Remove outliers using Z-score for price and mileage\n",
    "df_clean = df[(np.abs(stats.zscore(df['price_in_euro'])) < 9)]  # 4 is the higher threshold for outliers\n",
    "df_clean = df_clean[(np.abs(stats.zscore(df_clean['mileage_in_km'])) < 4)]  # Do the same for mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22f101fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CatBoost Model...\n",
      "CatBoost MAE: 3263.3470176493884\n",
      "Test R² - full datase withput Outliers: 0.929184192123229\n",
      "Test Set MSE - full dataset without Outliers: 48727422.47352347\n"
     ]
    }
   ],
   "source": [
    "# Example setup of columns, adjust based on your dataset structure\n",
    "target = 'price_in_euro'\n",
    "numerical_features = ['age', 'power_ps', 'fuel_consumption_l_100km', 'mileage_in_km']\n",
    "categorical_features = ['color', 'model', 'brand', 'fuel_type', 'transmission_type']\n",
    "\n",
    "# Splitting data into X and y\n",
    "X = df_clean[numerical_features + categorical_features]\n",
    "y = df_clean[target]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "### CatBoost Model ###\n",
    "print(\"Training CatBoost Model...\")\n",
    "catboost_model = CatBoostRegressor(cat_features=categorical_features, verbose=0, n_estimators=500, max_depth=None, grow_policy='Depthwise', bagging_temperature=100)  # Setting categorical features\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate CatBoost\n",
    "y_pred_catboost = catboost_model.predict(X_test)\n",
    "mae_catboost = mean_absolute_error(y_test, y_pred_catboost)\n",
    "print(f\"CatBoost MAE: {mae_catboost}\")\n",
    "\n",
    "test_r2 = r2_score(y_test, y_pred_catboost)\n",
    "print(f\"Test R² - full datase withput Outliers: {test_r2}\")\n",
    "mse_test = mean_squared_error(y_test, y_pred_catboost)\n",
    "print(f\"Test Set MSE - full dataset without Outliers: {mse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e20ecef",
   "metadata": {},
   "source": [
    "### Without colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab6f3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data \n",
    "#cleaned dataset\n",
    "df = pd.read_csv(\"auto_data_cleaned_16_09_2024.csv\")\n",
    "\n",
    "#  setup of features, adjust based on your dataset structure\n",
    "\n",
    "df=df.drop(columns=['color', 'year', 'offer_description'])\n",
    "\n",
    "\n",
    "# Remove outliers using Z-score for price and mileage\n",
    "df_clean = df[(np.abs(stats.zscore(df['price_in_euro'])) < 9)]  # 4 is the higher threshold for outliers\n",
    "df_clean = df_clean[(np.abs(stats.zscore(df_clean['mileage_in_km'])) < 4)]  # Do the same for mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61e5d342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CatBoost Model...\n",
      "CatBoost MAE: 3288.682265481608\n",
      "Test R² - full datase withput Outliers: 0.9182634710590439\n",
      "Test Set MSE - full dataset without Outliers: 54985339.42732238\n"
     ]
    }
   ],
   "source": [
    "# Example setup of columns, adjust based on your dataset structure\n",
    "target = 'price_in_euro'\n",
    "numerical_features = ['age', 'power_ps', 'fuel_consumption_l_100km', 'mileage_in_km']\n",
    "categorical_features = [ 'model', 'brand', 'fuel_type', 'transmission_type']\n",
    "\n",
    "# Splitting data into X and y\n",
    "X = df_clean[numerical_features + categorical_features]\n",
    "y = df_clean[target]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "### CatBoost Model ###\n",
    "print(\"Training CatBoost Model...\")\n",
    "catboost_model = CatBoostRegressor(cat_features=categorical_features, verbose=0, n_estimators=500, max_depth=None, grow_policy='Depthwise', bagging_temperature=100)  # Setting categorical features\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate CatBoost\n",
    "y_pred_catboost = catboost_model.predict(X_test)\n",
    "mae_catboost = mean_absolute_error(y_test, y_pred_catboost)\n",
    "print(f\"CatBoost MAE: {mae_catboost}\")\n",
    "\n",
    "test_r2 = r2_score(y_test, y_pred_catboost)\n",
    "print(f\"Test R² - full datase withput Outliers: {test_r2}\")\n",
    "mse_test = mean_squared_error(y_test, y_pred_catboost)\n",
    "print(f\"Test Set MSE - full dataset without Outliers: {mse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e15f60",
   "metadata": {},
   "source": [
    "## Lightgbm model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb14d480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM Model...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1054\n",
      "[LightGBM] [Info] Number of data points in the train set: 190641, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 25715.360715\n",
      "LightGBM MAE: 3928.7472695796605\n",
      "Test R² - full datase : 0.8709635363752204\n",
      "Test Set MSE - full dataset : 146176671.17697877\n"
     ]
    }
   ],
   "source": [
    "#cleaned dataset\n",
    "df = pd.read_csv(\"auto_data_cleaned_16_09_2024.csv\")\n",
    "\n",
    "# the models will be encoded by mean value of price of every model\n",
    "target_encoder = ce.TargetEncoder(cols=['model'])\n",
    "df['Modell_encoded'] = target_encoder.fit_transform(df['model'], df['price_in_euro'])  # 'Preis' ist die Zielvariable\n",
    "\n",
    "\n",
    "# the brand will be encoded by mean value of price of every model\n",
    "target_encoder = ce.TargetEncoder(cols=['brand'])\n",
    "df['Brand_encoded'] = target_encoder.fit_transform(df['brand'], df['price_in_euro'])  # 'Preis' ist die Zielvariable\n",
    "\n",
    "df=df.drop(columns=['year', 'offer_description', ])\n",
    "\n",
    "df = pd.get_dummies(df, columns=[ 'fuel_type', 'transmission_type','color'], dtype='int')\n",
    "\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X = df.drop(['price_in_euro', 'model', 'brand'], axis=1)  # Features\n",
    "y = df['price_in_euro']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "### LightGBM Model ###\n",
    "# Encoding categorical variables for LightGBM since it doesn’t handle string categories directly\n",
    "\n",
    "\n",
    "print(\"Training LightGBM Model...\")\n",
    "lgbm_model = LGBMRegressor()\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate LightGBM\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "mae_lgbm = mean_absolute_error(y_test, y_pred_lgbm)\n",
    "print(f\"LightGBM MAE: {mae_lgbm}\")\n",
    "\n",
    "\n",
    "test_r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
    "print(f\"Test R² - full datase : {test_r2_lgbm}\")\n",
    "mse_lgbm = mean_squared_error(y_test, y_pred_lgbm)\n",
    "print(f\"Test Set MSE - full dataset : {mse_lgbm}\")\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96535c06",
   "metadata": {},
   "source": [
    "### Dataset without extreme price values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93b49bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM Model...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 189092, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 23860.429669\n",
      "LightGBM MAE: 3286.47428153585\n",
      "Test R² - full dataset without Outliers : 0.9003591242450679\n",
      "Test Set MSE - full dataset without Outliers : 42454646.65125012\n"
     ]
    }
   ],
   "source": [
    "#cleaned dataset\n",
    "df = pd.read_csv(\"auto_data_cleaned_16_09_2024.csv\")\n",
    "\n",
    "# the models will be encoded by mean value of price of every model\n",
    "target_encoder = ce.TargetEncoder(cols=['model'])\n",
    "df['Modell_encoded'] = target_encoder.fit_transform(df['model'], df['price_in_euro'])  # 'Preis' ist die Zielvariable\n",
    "\n",
    "\n",
    "# the brand will be encoded by mean value of price of every model\n",
    "target_encoder = ce.TargetEncoder(cols=['brand'])\n",
    "df['Brand_encoded'] = target_encoder.fit_transform(df['brand'], df['price_in_euro'])  # 'Preis' ist die Zielvariable\n",
    "\n",
    "df=df.drop(columns=['year', 'offer_description', ])\n",
    "\n",
    "df = pd.get_dummies(df, columns=[ 'fuel_type', 'transmission_type','color'], dtype='int')\n",
    "\n",
    "\n",
    "# Remove outliers using Z-score for price and mileage\n",
    "df_clean = df[(np.abs(stats.zscore(df['price_in_euro'])) < 5)]  # 4 is the higher threshold for outliers\n",
    "df_clean = df_clean[(np.abs(stats.zscore(df_clean['mileage_in_km'])) < 4)]  # Do the same for mileage\n",
    "\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X = df_clean.drop(['price_in_euro', 'model', 'brand'], axis=1)  # Features\n",
    "y = df_clean['price_in_euro']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "### LightGBM Model ###\n",
    "# Encoding categorical variables for LightGBM since it doesn’t handle string categories directly\n",
    "\n",
    "\n",
    "print(\"Training LightGBM Model...\")\n",
    "lgbm_model = LGBMRegressor()\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate LightGBM\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "mae_lgbm = mean_absolute_error(y_test, y_pred_lgbm)\n",
    "print(f\"LightGBM MAE: {mae_lgbm}\")\n",
    "\n",
    "\n",
    "test_r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
    "print(f\"Test R² - full dataset without Outliers : {test_r2_lgbm}\")\n",
    "mse_lgbm = mean_squared_error(y_test, y_pred_lgbm)\n",
    "print(f\"Test Set MSE - full dataset without Outliers : {mse_lgbm}\")\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1553253",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy --upgrade --quiet\n",
    "\n",
    "# Step 4: Upgrade my numpy back to the latest version (if needed)\n",
    "#!pip install numpy --upgrade --quiet\n",
    "\n",
    "# Step 5: Restart the kernel again to apply the numpy upgrade\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
